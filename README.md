# WangChain

<div align="center">

**åŸºäºLangChainçš„ä¼ä¸šçº§LLMåº”ç”¨å¼€å‘æ¡†æ¶**

**Enterprise-Grade LLM Application Development Framework Based on LangChain**

[![Python Version](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

</div>

## ğŸ“– ç®€ä»‹ | Introduction

WangChainæ˜¯ä¸€ä¸ªåŸºäºLangChainæ„å»ºçš„ä¼ä¸šçº§å¤§è¯­è¨€æ¨¡å‹(LLM)åº”ç”¨å¼€å‘æ¡†æ¶ã€‚å®ƒé‡‡ç”¨é¢å‘å¯¹è±¡ç¼–ç¨‹å’Œè®¾è®¡æ¨¡å¼ï¼Œæä¾›é«˜æ€§èƒ½ã€é«˜å¯ç”¨æ€§ã€å®‰å…¨å¯é çš„è§£å†³æ–¹æ¡ˆã€‚

WangChain is an enterprise-grade Large Language Model (LLM) application development framework built on LangChain. It employs object-oriented programming and design patterns to provide high-performance, high-availability, and secure solutions.

## âœ¨ æ ¸å¿ƒç‰¹æ€§ | Key Features

### ğŸ—ï¸ è®¾è®¡æ¨¡å¼ | Design Patterns
- **å·¥å‚æ¨¡å¼ Factory Pattern**: çµæ´»åˆ›å»ºä¸åŒç±»å‹çš„LLMå®ä¾‹
- **æ„å»ºå™¨æ¨¡å¼ Builder Pattern**: ä¼˜é›…é…ç½®å¤æ‚å¯¹è±¡
- **å•ä¾‹æ¨¡å¼ Singleton Pattern**: å…¨å±€é…ç½®ç®¡ç†

### ğŸ” RAGæŠ€æœ¯ | RAG Technology
- **å¤šæ ¼å¼æ–‡æ¡£æ”¯æŒ Multi-format Document Support**: PDFã€TXTã€DOCXç­‰
- **å‘é‡å­˜å‚¨ Vector Stores**: æ”¯æŒChromaã€FAISSç­‰å¤šç§å‘é‡æ•°æ®åº“
- **æ™ºèƒ½æ£€ç´¢ Intelligent Retrieval**: åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦çš„æ–‡æ¡£æ£€ç´¢
- **é—®ç­”é“¾ Q&A Chain**: ç»“åˆæ£€ç´¢å’Œç”Ÿæˆçš„æ™ºèƒ½é—®ç­”

### ğŸ¤– æ™ºèƒ½ä»£ç† | Intelligent Agents
- **å·¥å…·é›†æˆ Tool Integration**: æœç´¢ã€è®¡ç®—å™¨ã€ç»´åŸºç™¾ç§‘ç­‰
- **ReActæ¡†æ¶ ReAct Framework**: æ¨ç†å’Œè¡ŒåŠ¨ç»“åˆçš„æ™ºèƒ½å†³ç­–
- **å¯æ‰©å±•æ¶æ„ Extensible Architecture**: è½»æ¾æ·»åŠ è‡ªå®šä¹‰å·¥å…·

### ğŸ”’ ä¼ä¸šçº§ç‰¹æ€§ | Enterprise Features
- **é…ç½®ç®¡ç† Configuration Management**: åŸºäºPydanticçš„ç±»å‹å®‰å…¨é…ç½®
- **é”™è¯¯å¤„ç† Error Handling**: å®Œå–„çš„å¼‚å¸¸å¤„ç†å’Œé‡è¯•æœºåˆ¶
- **æ—¥å¿—ç³»ç»Ÿ Logging System**: ç»Ÿä¸€çš„æ—¥å¿—ç®¡ç†
- **å®‰å…¨æ€§ Security**: APIå¯†é’¥éªŒè¯ã€è¾“å…¥æ ¡éªŒ

## ğŸš€ å¿«é€Ÿå¼€å§‹ | Quick Start

### å®‰è£… | Installation

```bash
# å…‹éš†ä»“åº“ Clone repository
git clone https://github.com/Puppy4388/WangChain.git
cd WangChain

# å®‰è£…ä¾èµ– Install dependencies
pip install -r requirements.txt

# æˆ–ç›´æ¥å®‰è£…åŒ… Or install package directly
pip install -e .
```

### é…ç½® | Configuration

1. å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿ Copy environment template:
```bash
cp .env.example .env
```

2. ç¼–è¾‘.envæ–‡ä»¶ï¼Œæ·»åŠ ä½ çš„APIå¯†é’¥ Edit .env file and add your API key:
```bash
OPENAI_API_KEY=your_openai_api_key_here
```

### åŸºç¡€ä½¿ç”¨ | Basic Usage

#### 1. LLMåŸºç¡€è°ƒç”¨ | Basic LLM Usage

```python
from wangchain.core import LLMFactory, LLMBuilder

# æ–¹æ³•1: ä½¿ç”¨å·¥å‚æ¨¡å¼ Method 1: Using Factory Pattern
llm = LLMFactory.create_llm(
    model_type="openai",
    temperature=0.7,
    model_name="gpt-3.5-turbo"
)

response = llm.invoke("ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹LangChain")
print(response.content)

# æ–¹æ³•2: ä½¿ç”¨æ„å»ºå™¨æ¨¡å¼ Method 2: Using Builder Pattern
llm = (LLMBuilder()
       .set_model_type("openai")
       .set_temperature(0.5)
       .set_max_tokens(1000)
       .build())
```

#### 2. RAGæ–‡æ¡£é—®ç­” | RAG Document Q&A

```python
from wangchain.rag import RAGRetriever, RAGChain

# åˆå§‹åŒ–RAGæ£€ç´¢å™¨ Initialize RAG retriever
retriever = RAGRetriever(
    vector_store_type="chroma",
    embedding_model="text-embedding-ada-002"
)

# åŠ è½½å¹¶ç´¢å¼•æ–‡æ¡£ Load and index documents
retriever.load_and_index_documents(["path/to/doc1.pdf", "path/to/doc2.txt"])

# åˆ›å»ºé—®ç­”é“¾ Create Q&A chain
rag_chain = RAGChain(retriever=retriever)

# æ‰§è¡ŒæŸ¥è¯¢ Execute query
result = rag_chain.query("æ–‡æ¡£çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ")
print(result['answer'])
```

#### 3. æ™ºèƒ½ä»£ç† | Intelligent Agent

```python
from wangchain.agents import AgentExecutor, AgentBuilder

# åˆ›å»ºAgent Create agent
agent = AgentExecutor(verbose=True)

# æ‰§è¡Œä»»åŠ¡ Execute task
result = agent.run("è¯·è®¡ç®—123 * 456çš„ç»“æœï¼Œå¹¶æœç´¢Pythonçš„æœ€æ–°ç‰ˆæœ¬")
print(result)

# ä½¿ç”¨æ„å»ºå™¨åˆ›å»ºè‡ªå®šä¹‰Agent Use builder to create custom agent
from wangchain.agents import ToolFactory

custom_agent = (AgentBuilder()
                .with_tools([
                    ToolFactory.create_calculator_tool(),
                    ToolFactory.create_search_tool()
                ])
                .set_verbose(True)
                .build())
```

## ğŸ“‚ é¡¹ç›®ç»“æ„ | Project Structure

```
WangChain/
â”œâ”€â”€ wangchain/              # æ ¸å¿ƒåŒ… Core package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core/              # æ ¸å¿ƒæ¨¡å— Core modules
â”‚   â”‚   â”œâ”€â”€ llm_factory.py # LLMå·¥å‚ LLM factory
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ rag/               # RAGæ¨¡å— RAG module
â”‚   â”‚   â”œâ”€â”€ retriever.py   # æ£€ç´¢å™¨ Retriever
â”‚   â”‚   â”œâ”€â”€ chain.py       # é—®ç­”é“¾ Q&A chain
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ agents/            # ä»£ç†æ¨¡å— Agents module
â”‚   â”‚   â”œâ”€â”€ agent_executor.py  # Agentæ‰§è¡Œå™¨
â”‚   â”‚   â”œâ”€â”€ tools.py       # å·¥å…·é›† Tools
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ config/            # é…ç½®æ¨¡å— Configuration
â”‚   â”‚   â”œâ”€â”€ settings.py    # é…ç½®ç®¡ç† Config management
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â””â”€â”€ utils/             # å·¥å…·æ¨¡å— Utilities
â”‚       â”œâ”€â”€ logger.py      # æ—¥å¿— Logging
â”‚       â”œâ”€â”€ errors.py      # é”™è¯¯å¤„ç† Error handling
â”‚       â””â”€â”€ __init__.py
â”œâ”€â”€ examples/              # ç¤ºä¾‹ä»£ç  Examples
â”‚   â”œâ”€â”€ basic_llm_example.py
â”‚   â”œâ”€â”€ rag_example.py
â”‚   â””â”€â”€ agent_example.py
â”œâ”€â”€ tests/                 # æµ‹è¯• Tests
â”‚   â”œâ”€â”€ test_config.py
â”‚   â”œâ”€â”€ test_core.py
â”‚   â””â”€â”€ test_utils.py
â”œâ”€â”€ requirements.txt       # ä¾èµ– Dependencies
â”œâ”€â”€ setup.py              # å®‰è£…é…ç½® Setup config
â”œâ”€â”€ .env.example          # ç¯å¢ƒå˜é‡æ¨¡æ¿ Env template
â””â”€â”€ README.md             # æ–‡æ¡£ Documentation
```

## ğŸ¯ è®¾è®¡æ¨¡å¼åº”ç”¨ | Design Pattern Applications

### å·¥å‚æ¨¡å¼ | Factory Pattern
```python
# LLMFactoryå’ŒVectorStoreFactoryä½¿ç”¨å·¥å‚æ¨¡å¼
# LLMFactory and VectorStoreFactory use Factory pattern
llm = LLMFactory.create_llm(model_type="openai")
vector_store = VectorStoreFactory.create_vector_store(store_type="chroma", ...)
```

### æ„å»ºå™¨æ¨¡å¼ | Builder Pattern
```python
# LLMBuilderå’ŒAgentBuilderä½¿ç”¨æ„å»ºå™¨æ¨¡å¼
# LLMBuilder and AgentBuilder use Builder pattern
llm = (LLMBuilder()
       .set_model_type("openai")
       .set_temperature(0.7)
       .build())
```

### å•ä¾‹æ¨¡å¼ | Singleton Pattern
```python
# ConfigManagerä½¿ç”¨å•ä¾‹æ¨¡å¼ç¡®ä¿å…¨å±€é…ç½®ä¸€è‡´
# ConfigManager uses Singleton pattern for global config consistency
config = ConfigManager()
```

## ğŸ§ª æµ‹è¯• | Testing

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯• Run all tests
pytest

# è¿è¡Œç‰¹å®šæµ‹è¯• Run specific tests
pytest tests/test_config.py

# æ˜¾ç¤ºè¦†ç›–ç‡ Show coverage
pytest --cov=wangchain
```

## ğŸ“š ç¤ºä¾‹ | Examples

æŸ¥çœ‹ `examples/` ç›®å½•è·å–æ›´å¤šç¤ºä¾‹ï¼š
Check the `examples/` directory for more examples:

- `basic_llm_example.py` - LLMåŸºç¡€ä½¿ç”¨ Basic LLM usage
- `rag_example.py` - RAGæ–‡æ¡£é—®ç­” RAG document Q&A
- `agent_example.py` - æ™ºèƒ½ä»£ç†ä½¿ç”¨ Intelligent agent usage

è¿è¡Œç¤ºä¾‹ Run examples:
```bash
python examples/basic_llm_example.py
python examples/rag_example.py
python examples/agent_example.py
```

## ğŸ”§ é…ç½®è¯´æ˜ | Configuration

### LLMé…ç½® | LLM Configuration
- `model_name`: æ¨¡å‹åç§° Model name (default: gpt-3.5-turbo)
- `temperature`: æ¸©åº¦å‚æ•° Temperature (0.0-2.0)
- `max_tokens`: æœ€å¤§tokenæ•° Max tokens
- `request_timeout`: è¯·æ±‚è¶…æ—¶ Request timeout (seconds)
- `max_retries`: æœ€å¤§é‡è¯•æ¬¡æ•° Max retries

### RAGé…ç½® | RAG Configuration
- `vector_store_type`: å‘é‡å­˜å‚¨ç±»å‹ Vector store type (chroma/faiss)
- `chunk_size`: æ–‡æ¡£åˆ†å—å¤§å° Chunk size
- `chunk_overlap`: åˆ†å—é‡å  Chunk overlap
- `top_k`: æ£€ç´¢æ–‡æ¡£æ•° Number of documents to retrieve

### Agenté…ç½® | Agent Configuration
- `max_iterations`: æœ€å¤§è¿­ä»£æ¬¡æ•° Max iterations
- `enable_search`: å¯ç”¨æœç´¢ Enable search tool
- `enable_calculator`: å¯ç”¨è®¡ç®—å™¨ Enable calculator tool
- `enable_wikipedia`: å¯ç”¨ç»´åŸºç™¾ç§‘ Enable Wikipedia tool

## ğŸ¤ è´¡çŒ® | Contributing

æ¬¢è¿è´¡çŒ®ï¼è¯·éšæ—¶æäº¤Pull Requestã€‚
Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ è®¸å¯è¯ | License

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details

## ğŸ“® è”ç³»æ–¹å¼ | Contact

- GitHub: [https://github.com/Puppy4388/WangChain](https://github.com/Puppy4388/WangChain)
- Issues: [https://github.com/Puppy4388/WangChain/issues](https://github.com/Puppy4388/WangChain/issues)

## ğŸ™ è‡´è°¢ | Acknowledgments

- [LangChain](https://github.com/langchain-ai/langchain) - æ ¸å¿ƒæ¡†æ¶ Core framework
- [OpenAI](https://openai.com/) - LLMæä¾›å•† LLM provider
- æ‰€æœ‰è´¡çŒ®è€… All contributors